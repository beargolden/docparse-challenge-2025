#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†åŸå§‹ jsonl (image + prefix + suffix) è½¬æ¢ä¸º LLaMA Factory å¤šæ¨¡æ€æ ¼å¼ã€‚
ç‰¹ç‚¹ï¼š
1. ä¿ç•™ prefix ä½œä¸º human æŒ‡ä»¤çš„ä¸€éƒ¨åˆ†ï¼›
2. suffix åŸæ ·è¾“å‡ºåˆ° gpt å›å¤ï¼›
3. è‡ªåŠ¨æ ¹æ®è¾“å…¥æ–‡ä»¶åé€‰æ‹© image è·¯å¾„å‰ç¼€ï¼š
   - train.jsonl â†’ vlm-challenge-update/image/train
   - eval.jsonl æˆ– val.jsonl â†’ vlm-challenge-update/image/eval
   - å…¶ä»–æƒ…å†µ â†’ vlm-challenge-update/image/other
4. ç»“æ„å®Œå…¨ç¬¦åˆ LLaMA Factory å¤šæ¨¡æ€è®­ç»ƒæ•°æ®æ ¼å¼ã€‚
"""

import json
import sys
from pathlib import Path
from tqdm import tqdm


def infer_image_root(input_path: Path) -> str:
    """æ ¹æ®æ–‡ä»¶åè‡ªåŠ¨æ¨æ–­ image æ ¹ç›®å½•è·¯å¾„"""
    name = input_path.stem.lower()
    if "train" in name:
        subset = "train"
    elif "eval" in name or "val" in name:
        subset = "eval"
    else:
        subset = "other"
    return f"/root/autodl-tmp/LLaMA-Factory/data/vlm-challenge-update/image/{subset}"


def convert_file(input_path, output_path, image_root=None):
    input_path = Path(input_path)
    output_path = Path(output_path)

    if not input_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_path}")
        sys.exit(1)

    # è‡ªåŠ¨æ¨æ–­ image è·¯å¾„å‰ç¼€
    if image_root is None:
        image_root = infer_image_root(input_path)
        print(f"ğŸ“ è‡ªåŠ¨æ£€æµ‹ image æ ¹ç›®å½•ï¼š{image_root}")

    image_root = image_root.rstrip("/")

    total = sum(1 for _ in open(input_path, "r", encoding="utf-8"))
    success, fail = 0, 0

    with open(input_path, "r", encoding="utf-8") as fin, \
            open(output_path, "w", encoding="utf-8") as fout:

        for line_no, line in enumerate(tqdm(fin, total=total, desc="Converting"), start=1):
            line = line.strip()
            if not line:
                continue

            try:
                obj = json.loads(line)
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡ç¬¬ {line_no} è¡Œï¼šæ— æ³•è§£æ JSON ({e})")
                fail += 1
                continue

            image = obj.get("image", "")
            prefix = obj.get("prefix", "")
            suffix = obj.get("suffix", "")

            # æ‹¼æ¥ image è·¯å¾„å‰ç¼€
            if image:
                image = f"{image_root}/{image.lstrip('/')}"

            if not prefix:
                print(f"âš ï¸ ç¬¬ {line_no} è¡Œç¼ºå°‘ prefix å­—æ®µï¼Œå·²ä½¿ç”¨ç©ºå­—ç¬¦ä¸²")
            if not suffix:
                print(f"âš ï¸ ç¬¬ {line_no} è¡Œç¼ºå°‘ suffix å­—æ®µï¼Œå·²ä½¿ç”¨ç©ºå­—ç¬¦ä¸²")

            sample = {
                "id": f"sample-{success + 1:04d}",
                "image": image,
                "conversations": [
                    {
                        "from": "human",
                        "value": f"<image>è¯·è§£æè¯¥æ–‡æ¡£å›¾åƒï¼Œè¾“å‡ºç¬¦åˆè¦æ±‚çš„{prefix}ç»“æ„ã€‚"
                    },
                    {
                        "from": "gpt",
                        "value": suffix
                    }
                ]
            }

            fout.write(json.dumps(sample, ensure_ascii=False) + "\n")
            success += 1

    print(f"\nâœ… è½¬æ¢å®Œæˆï¼šæˆåŠŸ {success} æ¡ï¼Œè·³è¿‡ {fail} æ¡")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶ï¼š{output_path.resolve()}")


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•ï¼špython convert_to_llama_factory.py <input.jsonl> <output.jsonl> [image_root]")
        print("è¯´æ˜ï¼šè‹¥æœªæŒ‡å®š image_rootï¼Œå°†è‡ªåŠ¨æ ¹æ®è¾“å…¥æ–‡ä»¶åæ¨æ–­ train / eval / other")
        sys.exit(1)

    input_path = sys.argv[1]
    output_path = sys.argv[2]
    image_root = sys.argv[3] if len(sys.argv) >= 4 else None

    convert_file(input_path, output_path, image_root)


if __name__ == "__main__":
    main()
